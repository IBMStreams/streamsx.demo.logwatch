/*
 * LogWatch
 * Scott Schneider, scott.a.s@us.ibm.com
 * Requires InfoSphere Streams 2.0 or higher.
 *
 * For further information, see the README.
 */

namespace com.ibm.streamsx.demo.logwatch.language;

/* Given a list of strings, produce one string that is the concatenation of 
 * them separated by spaces. */
rstring flatten(list<rstring> lst)
{
    mutable rstring str = "";
    for (rstring e in lst) {
        str += e + " ";
    }
    return str;
}

/* Tuple that represents a suspected breakin. */
type Suspect = timestamp diff, timestamp last, uint32 attempts, rstring rhost, rstring user;

/* For each remote host, look for failure $attempts in a period of $seconds. */
composite SuspectFind(input Failure; output Diff) {
    param
        expression<uint32> $attempts;
        expression<float64> $seconds;

    type FailureRange = timestamp max, timestamp min, rstring rhost, rstring user;

    graph
        stream<FailureRange> Range = Aggregate(Failure) {
            window Failure: tumbling, count($attempts), partitioned;
            param partitionBy: rhost;
            output Range: max = Max(time), min = Min(time), user = Max(user);
        }

        stream<FailureRange> Cutoff = Filter(Range) {
            param filter: max - min < (timestamp)$seconds;
        }

        stream<Suspect> Diff = Functor(Cutoff) {
            output Diff: diff = max - min, last = max, attempts = $attempts;
        }
}

/* Entry point of our application. We have to tell the compiler that "LogWatch" is our 
 * main composite. */
composite LogWatch {
    
    // Order matters: in a composite, the param clause (if present) must come before the 
    // type clause (if present), which must appear before the graph clause (if present).
    //
    // The param clause lists the parameters that the composite operator requires at 
    // invocation.
    param
        expression<rstring> $file: getSubmissionTimeValue("file");

    // All types that the composite operator uses. Each type describes the structure of a 
    // tuple - in fact, we could have wrapped each definition with tuple<...>. We use these 
    // types to describe streams.
    type
        LogLine = timestamp time, rstring hostname, rstring service, rstring message;
        Failure = timestamp time, rstring uid, rstring euid, rstring tty, rstring rhost, rstring user;
        Success = timestamp time, rstring user; 
        Breakin = timestamp time, rstring rhost, rstring user;

    // The stream graph of this composite operator.
    graph
        // How to read this: 
        // 
        // We are invoking the operator FileSource while specifying its parameters file, format and 
        // compression. The file parameter is given as $file, which is actually a parameter in this 
        // composite, defined above. The parameters "line" and "gzip" are constants defined by the 
        // FileSource operator. This operator invocation has no input stream.
        //
        // This operator invocation produces one output stream, which we call RawLines. The tuples on 
        // the RawLine stream have type tuple<rstring line>. In our tuple type, BOTH "rstring" and 
        // "line" are significant. That is, the type tuple<rstring other> is NOT the same type.
        stream<rstring line> RawLines = FileSource() {
            param file: $file;
                  format: line;
                  compression: gzip;
        }

        // Process the raw log line into a service-agnostic tuple.
        //
        // Custom operators are special operators that allow us to explicitly submit tuples. 
        stream<LogLine> ParsedLines = Custom(RawLines) {
            logic onTuple RawLines: {
                list<rstring> tokens = tokenize(line, " ", false);
                timestamp t = timeStringtoTimestamp(tokens[1] + "-" + 
                                                    upper(tokens[0]) + "-2011", 
                                                    tokens[2] + ".0", true);

                // How to read this: we are submitting the tuple constructed inside the 
                // curly brackets to the port for ParsedLines.
                submit({time = t, hostname = tokens[3], service = tokens[4], 
                        message = flatten(tokens[5:])}, 
                       ParsedLines);
            }
        }

        // Find all of the sshd authentication failures.
        stream<LogLine> RawFailures = Filter(ParsedLines) {
            param filter: findFirst(service, "sshd", 0) != -1 && 
                          findFirst(message, "authentication failure", 0) != -1;
        }

        // Process the authentication failure messages into tuples.
        stream<Failure> Failures = Custom(RawFailures) {
            logic onTuple RawFailures: {
                list<rstring> tokens = tokenize(message, ";", false);
                list<rstring> values = tokenize(tokens[1], "= ", false);

                submit({time = RawFailures.time, uid = values[2], 
                        euid = values[4], tty = values[6], rhost = values[9], 
                        user = size(values) == 12 ? values[11]: ""}, 
                       Failures);
            }
        }

        // Aggregate authentication failures with varying time granularities.
        stream<Suspect> LongTerm = SuspectFind(Failures) {
            param attempts: 300u;
                  seconds: 3600.0;
        }

        stream<Suspect> MediumTerm = SuspectFind(Failures) {
            param attempts: 50u;
                  seconds: 600.0;
        }

        stream<Suspect> RealTime = SuspectFind(Failures) {
            param attempts: 5u;
                  seconds: 60.0;
        }

        // Find all of the successful logins.
        stream<LogLine> RawSuccesses = Filter(ParsedLines) {
            param filter: findFirst(service, "sshd", 0) != -1 && 
                          findFirst(message, "session opened for user", 0) != -1;
        }

        // Who logged in?
        stream<Success> Successes = Functor(RawSuccesses) {
            output Successes: user = tokenize(regexMatch(message, "user .* by")[0], " ", false)[1];
        }

        // Correlate the realtime failures with the successful logins. If the 
        // username of the realtime failures matches up with a successful login 
        // from the past 60 seconds, flag it as a breakin.
        stream<Breakin> Breakins = Join(RealTime; Successes) {
            window RealTime: sliding, count(1);
                   Successes: sliding, count(1);
            param match: Successes.user == RealTime.user && 
                         diffAsSecs(Successes.time, RealTime.last) < 60.0;
            output Breakins: time = Successes.time, rhost = RealTime.rhost, user = Successes.user;
        }
        
        // The above is quite natural, but it's not actually deterministic - you can 
        // get different answers if the rates on the RealTime and Successes streams 
        // are different. The below call uses a hand-written deterministic join, but it's 
        // much harder to understand.
        /*
        stream<Breakin> Breakins = DeterministicJoin(RealTime; Successes) {
            param otype: Breakin;    
        }
        */

        // Sinks have no output stream, which we indicate with ().
        () as LongTermWriter = FileSink(LongTerm) {
            param file: "LongTerm.txt";
                  format: txt;
        }

        () as MediumTermWriter = FileSink(MediumTerm) {
            param file: "MediumTerm.txt";
                  format: txt;
        }

        () as RealTimeWriter = FileSink(RealTime) {
            param file: "RealTime.txt";
                  format: txt;
        }

        () as BreakinsWriter = FileSink(Breakins) {
            param file: "Breakins.txt";
                  format: txt;
        }
}
